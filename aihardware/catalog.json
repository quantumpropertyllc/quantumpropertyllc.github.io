{
    "hardware_bundles": [
        {
            "id": "entry_amazon_cyberpower",
            "name": "Entry Tier - CyberPowerPC Gamer Xtreme",
            "gpu": "RTX 4060 Ti (16GB VRAM)",
            "price": 1099.99,
            "vram": 16,
            "best_for": "Small Business & Customer Service Bots",
            "partner_name": "Amazon",
            "purchase_url": "https://www.amazon.com/dp/B0C7M8XN6S/?tag=queencityai-20",
            "image_url": "https://m.media-amazon.com/images/I/71fV9p-8O9L._AC_SL1500_.jpg"
        },
        {
            "id": "mid_tier_skytech",
            "name": "Mid-Tier - Skytech King 95",
            "gpu": "RTX 5070 Ti (16GB GDDR7)",
            "price": 2699.99,
            "vram": 16,
            "best_for": "Fast Inference & Llama 8B Specialist",
            "partner_name": "Amazon",
            "purchase_url": "https://www.amazon.com/dp/B0DLN909X1/?tag=queencityai-20",
            "image_url": "https://m.media-amazon.com/images/I/81+Xl9Z-MGL._AC_SL1500_.jpg"
        },
        {
            "id": "pro_tier_asus_rog",
            "name": "Professional Tier - ASUS ROG G700",
            "gpu": "RTX 5080 (16GB GDDR7)",
            "price": 2749.99,
            "vram": 16,
            "best_for": "Multi-Agent AI & Coding Assistants",
            "partner_name": "Amazon",
            "purchase_url": "https://www.amazon.com/dp/B0D1V3N5K4/?tag=queencityai-20",
            "image_url": "https://m.media-amazon.com/images/I/71p7eKk8IuL._AC_SL1500_.jpg"
        },
        {
            "id": "ultimate_amazon_msi",
            "name": "Ultimate Tier - MSI Aegis RS2",
            "gpu": "RTX 5090 (32GB GDDR7 VRAM)",
            "price": 4899.99,
            "vram": 32,
            "best_for": "Legal/Medical Firms & 70B+ Model Reasoning",
            "partner_name": "Amazon",
            "purchase_url": "https://www.amazon.com/dp/B0DZ909XLM/?tag=queencityai-20",
            "image_url": "https://m.media-amazon.com/images/I/81WjX8rUvCL._AC_SL1500_.jpg"
        },
        {
            "id": "creative_tier_mac_studio_m4",
            "name": "Creative Tier - Mac Studio M4 Max",
            "gpu": "M4 Max (128GB Unified Memory)",
            "price": 3999.00,
            "vram": 128,
            "best_for": "Massive Context & Apple Ecosystem",
            "partner_name": "Amazon",
            "purchase_url": "https://www.amazon.com/dp/B0DJM5X9LV/?tag=queencityai-20",
            "image_url": "https://m.media-amazon.com/images/I/51f9SDRyRML._AC_SL1500_.jpg"
        }
    ],
    "ai_models": [
        {
            "id": "llama-3.1-8b",
            "name": "Llama 3.1 8B",
            "family": "Meta Llama",
            "parameter_size": "8B",
            "context_window": 128000,
            "is_open_source": true,
            "best_for": [
                "chatbot",
                "document_review",
                "data_analysis"
            ],
            "min_vram": 8,
            "parameters": 8.0,
            "model_url": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
            "id": "mistral-7b",
            "name": "Mistral 7B",
            "family": "Mistral AI",
            "parameter_size": "7B",
            "context_window": 32000,
            "is_open_source": true,
            "best_for": [
                "chatbot",
                "data_analysis"
            ],
            "min_vram": 7,
            "parameters": 7.0,
            "model_url": "https://huggingface.co/mistralai/Mistral-7B-v0.1"
        },
        {
            "id": "llama-3.1-70b",
            "name": "Llama 3.1 70B",
            "family": "Meta Llama",
            "parameter_size": "70B",
            "context_window": 128000,
            "is_open_source": true,
            "best_for": [
                "coding",
                "legal",
                "medical"
            ],
            "min_vram": 40,
            "parameters": 70.0,
            "model_url": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
            "id": "deepseek-coder-v3",
            "name": "DeepSeek Coder V3",
            "family": "DeepSeek",
            "parameter_size": "33B",
            "context_window": 64000,
            "is_open_source": true,
            "best_for": [
                "coding"
            ],
            "min_vram": 24,
            "parameters": 33.0,
            "model_url": "https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct"
        },
        {
            "id": "llama-3.2-vision",
            "name": "Llama 3.2 Vision 11B",
            "family": "Meta Llama",
            "parameter_size": "11B",
            "context_window": 128000,
            "is_open_source": true,
            "best_for": [
                "image_gen",
                "document_review"
            ],
            "min_vram": 12,
            "parameters": 11.0,
            "model_url": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision"
        }
    ]
}
